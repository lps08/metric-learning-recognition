{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from pytorch_metric_learning import losses\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the device for PyTorch operations based on GPU availability.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the device, either 'cuda:0' if a CUDA-compatible GPU is available,\n",
    "        or 'cpu' if no GPU is available.\n",
    "\n",
    "    Example:\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    Using device: cuda:0 (if a GPU is available)\n",
    "    Using device: cpu (if no GPU is available)\n",
    "    \"\"\"\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset_path:str, batch_size:int, num_workers:int):\n",
    "    \"\"\"\n",
    "    Preprocesses a dataset of images for training and testing.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): The path to the dataset containing image files.\n",
    "        batch_size (int): The batch size for the data loaders.\n",
    "        num_workers (int): The number of worker processes for data loading.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - train_loader (DataLoader): DataLoader for the training dataset.\n",
    "            - test_loader (DataLoader): DataLoader for the testing dataset.\n",
    "            - class_to_name (dict): A dictionary mapping class indices to class names.\n",
    "            - classes (list): A list of class names in the dataset.\n",
    "\n",
    "    This function loads the dataset from the specified path, preprocesses the images, splits them into training and testing sets,\n",
    "    and creates data loaders for both sets. It also provides a mapping of class indices to class names and returns the list\n",
    "    of class names in the dataset.\n",
    "\n",
    "    The image preprocessing includes resizing, horizontal flipping, random rotation, elastic transformation, perspective transformation,\n",
    "    converting to tensors, and normalization.\n",
    "\n",
    "    Example usage:\n",
    "    train_loader, test_loader, class_to_name, classes = preprocess_dataset('data/dataset', batch_size=32, num_workers=4)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        # transforms.ElasticTransform(),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Loading the dataset\n",
    "    dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "    # Splitting the dataset into train and test\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), int(0.2 * len(dataset))])\n",
    "\n",
    "    # Creating dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "    num_classes = len(dataset.classes)\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "\n",
    "    class_to_name = {i: class_name for i, class_name in enumerate(dataset.classes)}\n",
    "\n",
    "    return train_loader, test_loader, class_to_name, dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_size, lr=0.001):\n",
    "    \"\"\"\n",
    "    Build a custom deep learning model for extracting embeddings from images.\n",
    "\n",
    "    Args:\n",
    "        embedding_size (int): The size of the embedding layer's output.\n",
    "        lr (float, optional): The learning rate for the optimizer (default is 0.001).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - model (nn.Module): The custom deep learning model for image embedding extraction.\n",
    "            - optimizer (torch.optim.Optimizer): The optimizer used for model training.\n",
    "\n",
    "    This function constructs a custom deep learning model based on the ResNet-50 architecture. It removes the last dense layer\n",
    "    and replaces it with a new fully connected layer with an output size specified by `embedding_size`.\n",
    "\n",
    "    The model is specifically designed for extracting feature embeddings from images, making it suitable for various computer\n",
    "    vision tasks.\n",
    "\n",
    "    Example usage:\n",
    "    model, optimizer = build_model(embedding_size=128, lr=0.001)\n",
    "    \"\"\"\n",
    "    # getting the device\n",
    "    device = get_device()\n",
    "\n",
    "    # Defining the model\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=embedding_size)  # Removing the last dense layer\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_labels(embeddings, labels, path, embedding_file_name, labels_file_name):\n",
    "    \"\"\"\n",
    "    Save feature embeddings and corresponding labels to specified files.\n",
    "\n",
    "    Args:\n",
    "        embeddings (torch.Tensor): Feature embeddings to be saved.\n",
    "        labels (torch.Tensor): Corresponding labels for the feature embeddings.\n",
    "        path (str): The directory path where the files will be saved.\n",
    "        embedding_file_name (str): The filename for saving feature embeddings.\n",
    "        labels_file_name (str): The filename for saving labels.\n",
    "\n",
    "    This function checks if the specified directory path exists; if not, it creates the directory.\n",
    "    It then saves the feature embeddings and labels to separate files in the specified directory.\n",
    "\n",
    "    Example usage:\n",
    "    save_embeddings_labels(embeddings, labels, '/path/to/save', 'embeddings.pth', 'labels.pth')\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    torch.save(embeddings, os.path.join(path, embedding_file_name))\n",
    "    torch.save(labels, os.path.join(path, labels_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, index_to_class_dict, loss_fn, optimizer, epochs, embeddings_save_dir, model_out_path):\n",
    "    \"\"\"\n",
    "    Train a deep learning model using CosFace and ArcFace loss functions and save embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The deep learning model to be trained.\n",
    "        cosface_loss (torch.nn.Module): The CosFace loss function.\n",
    "        arcface_loss (torch.nn.Module): The ArcFace loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer for model training.\n",
    "        epochs (int): The number of training epochs.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        class_to_name (dict): A dictionary mapping class indices to class names.\n",
    "        embeddings_save_dir (str): The directory path to save embeddings and labels.\n",
    "        model_out_path (str): The file path to save the trained model.\n",
    "\n",
    "    This function performs the training loop for the specified number of epochs using the provided model, loss functions,\n",
    "    optimizer, and data loader. During each epoch, feature embeddings are extracted, and the combined loss is calculated\n",
    "    using CosFace and ArcFace losses. Embeddings and labels are saved at the end of each epoch. The trained model is saved\n",
    "    to the specified file path.\n",
    "\n",
    "    Example usage:\n",
    "    train(model, cosface_loss, arcface_loss, optimizer, 10, train_loader, class_to_name, '/path/to/save', 'model.pth')\n",
    "    \"\"\"\n",
    "    # Getting the device\n",
    "    device = get_device()\n",
    "\n",
    "    # Starting training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Initialize lists to store embeddings and labels\n",
    "        train_embeddings = []\n",
    "        train_labels = []\n",
    "\n",
    "        # Iterating over the batches of training data\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Extracting the features from the images\n",
    "            features = model(images)\n",
    "\n",
    "            # Calculate the CosFaceLoss and ArcFaceLoss\n",
    "            # loss = combined_loss_fn(features, labels, cosface_loss, arcface_loss)\n",
    "            loss = loss_fn(features, labels)\n",
    "\n",
    "            # Storing embeddings and labels for this batch\n",
    "            train_embeddings.extend(features)\n",
    "            train_labels.extend([index_to_class_dict[i.item()] for i in labels])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Printing the progress\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs} - Iteration {i + 1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "            \n",
    "        # Save embeddings and labels at the end of each epoch\n",
    "        save_embeddings_labels(\n",
    "            embeddings=torch.stack(train_embeddings,dim=0),\n",
    "            labels=train_labels,\n",
    "            path=embeddings_save_dir,\n",
    "            embedding_file_name=f\"train_embeddings_epoch_{epoch}.pt\",\n",
    "            labels_file_name=f\"train_labels_epoch_{epoch}.pt\"\n",
    "        )\n",
    "\n",
    "        # Clear the lists to release GPU memory\n",
    "        train_embeddings.clear()\n",
    "        train_labels.clear()\n",
    "\n",
    "    # Save the model after training\n",
    "    torch.save(model.state_dict(), model_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataset_path = \"post-processed\"\n",
    "num_epochs = 20\n",
    "embeddings_save_dir = 'embeddings/'\n",
    "embedding_size =  512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2996\n",
      "Epoch 1/20 - Iteration 1/75 - Loss: 12.2104\n",
      "Epoch 1/20 - Iteration 51/75 - Loss: 9.3830\n",
      "Epoch 2/20 - Iteration 1/75 - Loss: 8.2994\n",
      "Epoch 2/20 - Iteration 51/75 - Loss: 7.9286\n",
      "Epoch 3/20 - Iteration 1/75 - Loss: 5.6080\n",
      "Epoch 3/20 - Iteration 51/75 - Loss: 6.0126\n",
      "Epoch 4/20 - Iteration 1/75 - Loss: 3.2437\n",
      "Epoch 4/20 - Iteration 51/75 - Loss: 4.6735\n",
      "Epoch 5/20 - Iteration 1/75 - Loss: 2.3007\n",
      "Epoch 5/20 - Iteration 51/75 - Loss: 2.9967\n",
      "Epoch 6/20 - Iteration 1/75 - Loss: 0.9751\n",
      "Epoch 6/20 - Iteration 51/75 - Loss: 1.6555\n",
      "Epoch 7/20 - Iteration 1/75 - Loss: 0.3368\n",
      "Epoch 7/20 - Iteration 51/75 - Loss: 0.4562\n",
      "Epoch 8/20 - Iteration 1/75 - Loss: 0.1894\n",
      "Epoch 8/20 - Iteration 51/75 - Loss: 0.2522\n",
      "Epoch 9/20 - Iteration 1/75 - Loss: 0.1406\n",
      "Epoch 9/20 - Iteration 51/75 - Loss: 0.1656\n",
      "Epoch 10/20 - Iteration 1/75 - Loss: 0.0971\n",
      "Epoch 10/20 - Iteration 51/75 - Loss: 0.1182\n",
      "Epoch 11/20 - Iteration 1/75 - Loss: 0.1381\n",
      "Epoch 11/20 - Iteration 51/75 - Loss: 0.0784\n",
      "Epoch 12/20 - Iteration 1/75 - Loss: 0.0318\n",
      "Epoch 12/20 - Iteration 51/75 - Loss: 0.0524\n",
      "Epoch 13/20 - Iteration 1/75 - Loss: 0.0394\n",
      "Epoch 13/20 - Iteration 51/75 - Loss: 0.1262\n",
      "Epoch 14/20 - Iteration 1/75 - Loss: 0.1570\n",
      "Epoch 14/20 - Iteration 51/75 - Loss: 0.0187\n",
      "Epoch 15/20 - Iteration 1/75 - Loss: 0.1052\n",
      "Epoch 15/20 - Iteration 51/75 - Loss: 0.0263\n",
      "Epoch 16/20 - Iteration 1/75 - Loss: 0.0691\n",
      "Epoch 16/20 - Iteration 51/75 - Loss: 0.0747\n",
      "Epoch 17/20 - Iteration 1/75 - Loss: 0.0596\n",
      "Epoch 17/20 - Iteration 51/75 - Loss: 0.0990\n",
      "Epoch 18/20 - Iteration 1/75 - Loss: 0.0527\n",
      "Epoch 18/20 - Iteration 51/75 - Loss: 0.0687\n",
      "Epoch 19/20 - Iteration 1/75 - Loss: 0.1097\n",
      "Epoch 19/20 - Iteration 51/75 - Loss: 0.3044\n",
      "Epoch 20/20 - Iteration 1/75 - Loss: 0.1568\n",
      "Epoch 20/20 - Iteration 51/75 - Loss: 0.3017\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, class_to_name, classes = preprocess_dataset(dataset_path=dataset_path, batch_size=batch_size, num_workers=4)\n",
    "# Building the model\n",
    "model, optimizer = build_model(embedding_size=embedding_size)\n",
    "# Defining the CosFaceLoss\n",
    "# cosface_loss = losses.CosFaceLoss(num_classes=len(classes), embedding_size=embedding_size, margin=0.1)\n",
    "# Defining ArcFaceLoss\n",
    "arcface_loss = losses.ArcFaceLoss(num_classes=len(classes), embedding_size=embedding_size, margin=0.1)\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    index_to_class_dict=class_to_name,\n",
    "    loss_fn=arcface_loss,\n",
    "    optimizer=optimizer,\n",
    "    epochs=num_epochs,\n",
    "    embeddings_save_dir=embeddings_save_dir,\n",
    "    model_out_path=\"model.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_labels(path):\n",
    "    \"\"\"\n",
    "    Load feature embeddings and corresponding labels from saved files.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory path where the embeddings and labels are saved.\n",
    "        num_epochs (int): The number of epochs for which embeddings and labels were saved.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - train_embeddings (torch.Tensor): Feature embeddings loaded from saved files.\n",
    "            - train_labels (list): Corresponding labels loaded from saved files.\n",
    "\n",
    "    This function loads feature embeddings and labels from saved files for the specified number of epochs.\n",
    "    The loaded embeddings are converted to a torch.Tensor and returned, along with the list of labels.\n",
    "\n",
    "    Example usage:\n",
    "    train_embeddings, train_labels = load_embeddings_labels('/path/to/embeddings', num_epochs=10)\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    train_embeddings, train_labels = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        embedding = torch.load(os.path.join(path, f'train_embeddings_epoch_{epoch}.pt')).to(device)\n",
    "        label = torch.load(os.path.join(path, f'train_labels_epoch_{epoch}.pt'))\n",
    "\n",
    "        train_embeddings.extend(embedding)\n",
    "        train_labels.extend(label)\n",
    "\n",
    "    train_embeddings = torch.stack(train_embeddings, dim=0).to(device)\n",
    "\n",
    "    return train_embeddings, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, embedding_size):\n",
    "    \"\"\"\n",
    "    Load a previously trained deep learning model and its optimizer from a saved checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The file path to the saved model checkpoint.\n",
    "        embedding_size (int): The size of the embedding layer's output.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - model (nn.Module): The loaded deep learning model.\n",
    "            - optimizer (torch.optim.Optimizer): The loaded optimizer associated with the model.\n",
    "\n",
    "    This function loads a previously trained deep learning model and its optimizer from a saved checkpoint file.\n",
    "    The model architecture should match the one used when the checkpoint was saved, and it is configured for the specified\n",
    "    embedding size. The loaded model and optimizer are returned as a tuple.\n",
    "\n",
    "    Example usage:\n",
    "    model, optimizer = load_model('saved_model_checkpoint.pth', embedding_size=128)\n",
    "    \"\"\"\n",
    "    model, optimizer = build_model(\n",
    "        embedding_size = embedding_size,\n",
    "    )\n",
    "    # Load the saved model state dictionary\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings, train_labels = load_embeddings_labels(embeddings_save_dir)\n",
    "\n",
    "model, optimizer = load_model(\n",
    "    model_path=\"model.pth\",\n",
    "    embedding_size=embedding_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classe predita é: Alvaro_Uribe --> 0.5723316669464111\n"
     ]
    }
   ],
   "source": [
    "def predict_face(model, image_path, embeddings, labels):\n",
    "    \"\"\"\n",
    "    Perform face recognition prediction using a trained model and saved embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained deep learning model for feature extraction.\n",
    "        image_path (str): The file path to the image to be recognized.\n",
    "        embeddings (torch.Tensor): Feature embeddings of known faces.\n",
    "        labels (list): Corresponding labels for the known faces.\n",
    "\n",
    "    This function loads and preprocesses an image, extracts its feature embedding using the provided model,\n",
    "    and calculates the cosine similarity between the input embedding and known embeddings. It then predicts\n",
    "    the class (label) of the most similar face and prints the predicted class.\n",
    "\n",
    "    Example usage:\n",
    "    predict_face(model, 'image_to_recognize.jpg', known_embeddings, known_labels)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = get_device()\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(128),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ElasticTransform(),\n",
    "            transforms.RandomPerspective(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    input_image = transform(image).to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        input_image = input_image.unsqueeze(0).to(device)\n",
    "        input_embedding = model(input_image)\n",
    "\n",
    "    # Calcula a similaridade entres os vetores de embeddings\n",
    "    similarities = F.cosine_similarity(input_embedding, embeddings, dim=1)\n",
    "    most_similar_index = torch.argmax(similarities)\n",
    "\n",
    "    # Recupera a classe predita\n",
    "    predicted_class = labels[most_similar_index]\n",
    "\n",
    "    # Printa o nome da classe\n",
    "    print(f'A classe predita é: {predicted_class} --> {max(similarities)}')\n",
    "\n",
    "predict_face(\n",
    "    model=model,\n",
    "    image_path='post-processed/Alvaro_Uribe/Alvaro_Uribe_0002_0000.jpg',\n",
    "    embeddings=train_embeddings,\n",
    "    labels=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: new_person\n"
     ]
    }
   ],
   "source": [
    "def add_new_class(model, embeddings, labels, dataset_path, epochs, num_works=4):\n",
    "    \"\"\"\n",
    "    Add a new class to an existing face recognition model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained deep learning model for feature extraction.\n",
    "        embeddings (torch.Tensor): Feature embeddings of known faces.\n",
    "        labels (list): Corresponding labels for the known faces.\n",
    "        dataset_path (str): The directory path to the dataset containing images of the new class.\n",
    "        epochs (int): The number of training epochs on the new class data.\n",
    "        num_workers (int, optional): The number of worker processes for data loading (default is 4).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - embeddings (torch.Tensor): Updated feature embeddings, including the new class.\n",
    "            - labels (list): Updated list of labels, including the new class.\n",
    "\n",
    "    This function extends an existing face recognition model to include a new class by loading images of the new class,\n",
    "    extracting feature embeddings, and updating the existing embeddings and labels. The training process is repeated for\n",
    "    the specified number of epochs on the new class data.\n",
    "\n",
    "    Example usage:\n",
    "    updated_embeddings, updated_labels = add_new_class(model, known_embeddings, known_labels, 'new_class_data', 10)\n",
    "    \"\"\"\n",
    "    device=get_device()\n",
    "    model.eval()\n",
    "\n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        # transforms.ElasticTransform(),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Loading the dataset\n",
    "    new_dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "    print(f\"Classes found: {', '.join(new_dataset.classes)}\")\n",
    "\n",
    "    # Criando os dataloaders\n",
    "    train_loader = DataLoader(new_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_works)\n",
    "\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        for _ in range(epochs):\n",
    "            # Inference on new class data\n",
    "            with torch.no_grad():\n",
    "                images = images.to(device)\n",
    "                new_embeddings = model(images)\n",
    "\n",
    "            # Update embeddings and labels\n",
    "            embeddings = torch.cat([embeddings, new_embeddings], dim=0)\n",
    "            labels.extend([new_dataset.classes[i]] * new_embeddings.size(0))\n",
    "\n",
    "    return embeddings, labels\n",
    "\n",
    "train_embeddings, train_labels = add_new_class(\n",
    "    model=model,\n",
    "    embeddings=train_embeddings,\n",
    "    labels=train_labels,\n",
    "    dataset_path='new_class',\n",
    "    epochs=num_epochs*5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classe predita é: new_person --> 0.8516544103622437\n",
      "A classe predita é: new_person --> 0.5857816934585571\n"
     ]
    }
   ],
   "source": [
    "predict_face(\n",
    "    model=model,\n",
    "    image_path='new_class/new_person/new_person_db.jpg',\n",
    "    embeddings=train_embeddings,\n",
    "    labels=train_labels\n",
    ")\n",
    "\n",
    "predict_face(\n",
    "    model=model,\n",
    "    image_path='new_person_infer.jpg',\n",
    "    embeddings=train_embeddings,\n",
    "    labels=train_labels\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deadalus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
